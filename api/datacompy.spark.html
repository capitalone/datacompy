<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html"><link rel="search" title="Search" href="../search.html"><link rel="prev" title="datacompy package" href="datacompy.html">

    <!-- Generated with Sphinx 8.1.3 and Furo 2025.09.25 -->
        <title>datacompy.spark package - datacompy 0.19.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=580074bf" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=8dab3a3b" />
    
    


<style>
  body {
    --color-code-background: #eeffcc;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle site navigation sidebar">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc" aria-label="Toggle table of contents sidebar">
<label class="overlay sidebar-overlay" for="__navigation"></label>
<label class="overlay toc-overlay" for="__toc"></label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <span class="icon"><svg><use href="#svg-menu"></use></svg></span>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">datacompy 0.19.1 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  <span class="sidebar-brand-text">datacompy 0.19.1 documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul>
<li class="toctree-l1"><a class="reference internal" href="../install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pandas_usage.html">Pandas Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark_usage.html">Spark Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../snowflake_usage.html">Snowflake Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../polars_usage.html">Polars Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fugue_usage.html">Fugue Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../template_guide.html">Template Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmark.html">Benchmarks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developer_instructions.html">Developer Instructions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul class="current">
<li class="toctree-l1 current has-children"><a class="reference internal" href="modules.html">datacompy</a><input aria-label="Toggle navigation of datacompy" checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul class="current">
<li class="toctree-l2 current has-children"><a class="reference internal" href="datacompy.html">datacompy package</a><input aria-label="Toggle navigation of datacompy package" checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul class="current">
<li class="toctree-l3 current current-page"><a class="current reference internal" href="#">datacompy.spark package</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/capitalone/datacompy">Github Repo</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="../_sources/api/datacompy.spark.rst.txt" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="datacompy-spark-package">
<h1>datacompy.spark package<a class="headerlink" href="#datacompy-spark-package" title="Link to this heading">¶</a></h1>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Link to this heading">¶</a></h2>
</section>
<section id="module-datacompy.spark.helper">
<span id="datacompy-spark-helper-module"></span><h2>datacompy.spark.helper module<a class="headerlink" href="#module-datacompy.spark.helper" title="Link to this heading">¶</a></h2>
<p>Helper function module contributed by Capital One’s Hydra Team.</p>
<p>Helper functions to assist in specific usecases where there is no columns to join
and use the row order of the datasets.</p>
<dl class="py function">
<dt class="sig sig-object py" id="datacompy.spark.helper.compare_by_row">
<span class="sig-prename descclassname"><span class="pre">datacompy.spark.helper.</span></span><span class="sig-name descname"><span class="pre">compare_by_row</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">spark_session</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">SparkSession</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_dataframe</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compare_dataframe</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">string2double_cols</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">abs_tol</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rel_tol</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">df1_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'df1'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">df2_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'df2'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_spaces</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_case</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cast_column_names_lower</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#datacompy.spark.sql.SparkSQLCompare" title="datacompy.spark.sql.SparkSQLCompare"><span class="pre">SparkSQLCompare</span></a></span></span><a class="headerlink" href="#datacompy.spark.helper.compare_by_row" title="Link to this definition">¶</a></dt>
<dd><p>Run a detailed analysis on specific usecases where there is no columns to join and use the row order of the datasets.</p>
<p>If you know which columns to join on then please use <code class="docutils literal notranslate"><span class="pre">SparkSQLCompare</span></code> directly as this is meant to help
support very specific helper usecases using row order contributed by Capital One’s Hydra Team.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>spark_session</strong> (<em>pyspark.sql.SparkSession</em>) – A <code class="docutils literal notranslate"><span class="pre">SparkSession</span></code> to be used to execute Spark commands in the comparison.</p></li>
<li><p><strong>base_dataframe</strong> (<em>pyspark.sql.DataFrame</em>) – Dataset to be compared against</p></li>
<li><p><strong>compare_dataframe</strong> (<em>pyspark.sql.DataFrame</em>) – dataset to compare</p></li>
<li><p><strong>string2double_cols</strong> (<em>List</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>) – The columns that contain numeric values but are stored as string types</p></li>
<li><p><strong>abs_tol</strong> (<em>float</em><em>, </em><em>optional</em>) – Absolute tolerance between two values.</p></li>
<li><p><strong>rel_tol</strong> (<em>float</em><em>, </em><em>optional</em>) – Relative tolerance between two values.</p></li>
<li><p><strong>df1_name</strong> (<em>str</em><em>, </em><em>optional</em>) – A string name for the first dataframe.  This allows the reporting to
print out an actual name instead of “df1”, and allows human users to
more easily track the dataframes.</p></li>
<li><p><strong>df2_name</strong> (<em>str</em><em>, </em><em>optional</em>) – A string name for the second dataframe</p></li>
<li><p><strong>ignore_spaces</strong> (<em>bool</em><em>, </em><em>optional</em>) – Flag to strip whitespace (including newlines) from string columns (including any join
columns)</p></li>
<li><p><strong>ignore_case</strong> (<em>bool</em><em>, </em><em>optional</em>) – Flag to ignore the case of string columns</p></li>
<li><p><strong>cast_column_names_lower</strong> (<em>bool</em><em>, </em><em>optional</em>) – Boolean indicator that controls of column names will be cast into lower case</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="#datacompy.spark.sql.SparkSQLCompare" title="datacompy.spark.sql.SparkSQLCompare">datacompy.spark.sql.SparkSQLCompare</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="datacompy.spark.helper.format_numeric_fields">
<span class="sig-prename descclassname"><span class="pre">datacompy.spark.helper.</span></span><span class="sig-name descname"><span class="pre">format_numeric_fields</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataFrame</span></span></span><a class="headerlink" href="#datacompy.spark.helper.format_numeric_fields" title="Link to this definition">¶</a></dt>
<dd><p>Round and truncate numeric fields to 5 decimal places.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>df</strong> (<em>pyspark.sql.DataFrame</em>) – The DataFrame to be formatted</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>pyspark.sql.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="datacompy.spark.helper.handle_numeric_strings">
<span class="sig-prename descclassname"><span class="pre">datacompy.spark.helper.</span></span><span class="sig-name descname"><span class="pre">handle_numeric_strings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">field_list</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataFrame</span></span></span><a class="headerlink" href="#datacompy.spark.helper.handle_numeric_strings" title="Link to this definition">¶</a></dt>
<dd><p>Convert columns in field_list from numeric strings to DoubleType.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> (<em>pyspark.sql.DataFrame</em>) – The DataFrame to be converted</p></li>
<li><p><strong>field_list</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – List of StringType columns to be converted to DoubleType</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>pyspark.sql.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="datacompy.spark.helper.sort_columns">
<span class="sig-prename descclassname"><span class="pre">datacompy.spark.helper.</span></span><span class="sig-name descname"><span class="pre">sort_columns</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">base_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compare_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataFrame</span></span></span><a class="headerlink" href="#datacompy.spark.helper.sort_columns" title="Link to this definition">¶</a></dt>
<dd><p>Sort both DataFrames by their columns to ensure consistent order.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>base_df</strong> (<em>pyspark.sql.DataFrame</em>) – The base DataFrame to be sorted</p></li>
<li><p><strong>compare_df</strong> (<em>pyspark.sql.DataFrame</em>) – The compare DataFrame to be sorted</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>pyspark.sql.DataFrame, pyspark.sql.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="datacompy.spark.helper.sort_rows">
<span class="sig-prename descclassname"><span class="pre">datacompy.spark.helper.</span></span><span class="sig-name descname"><span class="pre">sort_rows</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">base_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compare_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataFrame</span></span></span><a class="headerlink" href="#datacompy.spark.helper.sort_rows" title="Link to this definition">¶</a></dt>
<dd><p>Add new column to each DataFrame that numbers the rows, so they can be compared by row number.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>base_df</strong> (<em>pyspark.sql.DataFrame</em>) – The base DataFrame to be sorted</p></li>
<li><p><strong>compare_df</strong> (<em>pyspark.sql.DataFrame</em>) – The compare DataFrame to be sorted</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>pyspark.sql.DataFrame, pyspark.sql.DataFrame</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-datacompy.spark.sql">
<span id="datacompy-spark-sql-module"></span><h2>datacompy.spark.sql module<a class="headerlink" href="#module-datacompy.spark.sql" title="Link to this heading">¶</a></h2>
<p>Compare two PySpark SQL DataFrames.</p>
<p>Originally this package was meant to provide similar functionality to
PROC COMPARE in SAS - i.e. human-readable reporting on the difference between
two dataframes.</p>
<dl class="py class">
<dt class="sig sig-object py" id="datacompy.spark.sql.SparkSQLCompare">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">datacompy.spark.sql.</span></span><span class="sig-name descname"><span class="pre">SparkSQLCompare</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">spark_session</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">SparkSession</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">df1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">df2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">join_columns</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">abs_tol</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rel_tol</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">df1_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'df1'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">df2_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'df2'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_spaces</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_case</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cast_column_names_lower</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#datacompy.spark.sql.SparkSQLCompare" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="datacompy.html#datacompy.base.BaseCompare" title="datacompy.base.BaseCompare"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseCompare</span></code></a></p>
<p>Comparison class to be used to compare whether two Spark SQL dataframes are equal.</p>
<p>Both df1 and df2 should be dataframes containing all of the join_columns,
with unique column names. Differences between values are compared to
abs_tol + rel_tol * abs(df2[‘value’]).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>spark_session</strong> (<em>pyspark.sql.SparkSession</em>) – A <code class="docutils literal notranslate"><span class="pre">SparkSession</span></code> to be used to execute Spark commands in the comparison.</p></li>
<li><p><strong>df1</strong> (<em>pyspark.sql.DataFrame</em>) – First dataframe to check</p></li>
<li><p><strong>df2</strong> (<em>pyspark.sql.DataFrame</em>) – Second dataframe to check</p></li>
<li><p><strong>join_columns</strong> (<em>list</em><em> or </em><em>str</em><em>, </em><em>optional</em>) – Column(s) to join dataframes on.  If a string is passed in, that one
column will be used.</p></li>
<li><p><strong>abs_tol</strong> (<em>float</em><em> or </em><em>dict</em><em>, </em><em>optional</em>) – Absolute tolerance between two values. Can be either a float value applied to all columns,
or a dictionary mapping column names to specific tolerance values. The special key “default”
in the dictionary specifies the tolerance for columns not explicitly listed.</p></li>
<li><p><strong>rel_tol</strong> (<em>float</em><em> or </em><em>dict</em><em>, </em><em>optional</em>) – Relative tolerance between two values. Can be either a float value applied to all columns,
or a dictionary mapping column names to specific tolerance values. The special key “default”
in the dictionary specifies the tolerance for columns not explicitly listed.</p></li>
<li><p><strong>df1_name</strong> (<em>str</em><em>, </em><em>optional</em>) – A string name for the first dataframe.  This allows the reporting to
print out an actual name instead of “df1”, and allows human users to
more easily track the dataframes.</p></li>
<li><p><strong>df2_name</strong> (<em>str</em><em>, </em><em>optional</em>) – A string name for the second dataframe</p></li>
<li><p><strong>ignore_spaces</strong> (<em>bool</em><em>, </em><em>optional</em>) – Flag to strip whitespace (including newlines) from string columns (including any join
columns)</p></li>
<li><p><strong>ignore_case</strong> (<em>bool</em><em>, </em><em>optional</em>) – Flag to ignore the case of string columns</p></li>
<li><p><strong>cast_column_names_lower</strong> (<em>bool</em><em>, </em><em>optional</em>) – Boolean indicator that controls of column names will be cast into lower case</p></li>
</ul>
</dd>
<dt class="field-even">Variables<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>df1_unq_rows</strong> (<em>pyspark.sql.DataFrame</em>) – All records that are only in df1 (based on a join on join_columns)</p></li>
<li><p><strong>df2_unq_rows</strong> (<em>pyspark.sql.DataFrame</em>) – All records that are only in df2 (based on a join on join_columns)</p></li>
<li><p><strong>intersect_rows</strong> (<em>pyspark.sql.DataFrame</em>) – All records that are in both df1 and df2</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="datacompy.spark.sql.SparkSQLCompare.all_columns_match">
<span class="sig-name descname"><span class="pre">all_columns_match</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#datacompy.spark.sql.SparkSQLCompare.all_columns_match" title="Link to this definition">¶</a></dt>
<dd><p>Whether the columns all match in the dataframes.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>True if all columns in df1 are in df2 and vice versa</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="datacompy.spark.sql.SparkSQLCompare.all_mismatch">
<span class="sig-name descname"><span class="pre">all_mismatch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ignore_matching_cols</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataFrame</span></span></span><a class="headerlink" href="#datacompy.spark.sql.SparkSQLCompare.all_mismatch" title="Link to this definition">¶</a></dt>
<dd><p>Get all rows with any columns that have a mismatch.</p>
<p>Returns all df1 and df2 versions of the columns and join
columns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ignore_matching_cols</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether showing the matching columns in the output or not. The default is False.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>All rows of the intersection dataframe, containing any columns, that don’t match.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>pyspark.sql.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="datacompy.spark.sql.SparkSQLCompare.all_rows_overlap">
<span class="sig-name descname"><span class="pre">all_rows_overlap</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#datacompy.spark.sql.SparkSQLCompare.all_rows_overlap" title="Link to this definition">¶</a></dt>
<dd><p>Whether the rows are all present in both dataframes.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>True if all rows in df1 are in df2 and vice versa (based on
existence for join option)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="datacompy.spark.sql.SparkSQLCompare.count_matching_rows">
<span class="sig-name descname"><span class="pre">count_matching_rows</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#datacompy.spark.sql.SparkSQLCompare.count_matching_rows" title="Link to this definition">¶</a></dt>
<dd><p>Count the number of rows match (on overlapping fields).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Number of matching rows</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="datacompy.spark.sql.SparkSQLCompare.df1">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">df1</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">DataFrame</span></em><a class="headerlink" href="#datacompy.spark.sql.SparkSQLCompare.df1" title="Link to this definition">¶</a></dt>
<dd><p>Get the first dataframe.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="datacompy.spark.sql.SparkSQLCompare.df1_unq_columns">
<span class="sig-name descname"><span class="pre">df1_unq_columns</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">OrderedSet</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#datacompy.spark.sql.SparkSQLCompare.df1_unq_columns" title="Link to this definition">¶</a></dt>
<dd><p>Get columns that are unique to df1.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="datacompy.spark.sql.SparkSQLCompare.df2">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">df2</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">DataFrame</span></em><a class="headerlink" href="#datacompy.spark.sql.SparkSQLCompare.df2" title="Link to this definition">¶</a></dt>
<dd><p>Get the second dataframe.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="datacompy.spark.sql.SparkSQLCompare.df2_unq_columns">
<span class="sig-name descname"><span class="pre">df2_unq_columns</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">OrderedSet</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#datacompy.spark.sql.SparkSQLCompare.df2_unq_columns" title="Link to this definition">¶</a></dt>
<dd><p>Get columns that are unique to df2.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="datacompy.spark.sql.SparkSQLCompare.intersect_columns">
<span class="sig-name descname"><span class="pre">intersect_columns</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">OrderedSet</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#datacompy.spark.sql.SparkSQLCompare.intersect_columns" title="Link to this definition">¶</a></dt>
<dd><p>Get columns that are shared between the two dataframes.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="datacompy.spark.sql.SparkSQLCompare.intersect_rows_match">
<span class="sig-name descname"><span class="pre">intersect_rows_match</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#datacompy.spark.sql.SparkSQLCompare.intersect_rows_match" title="Link to this definition">¶</a></dt>
<dd><p>Check whether the intersect rows all match.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="datacompy.spark.sql.SparkSQLCompare.matches">
<span class="sig-name descname"><span class="pre">matches</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ignore_extra_columns</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#datacompy.spark.sql.SparkSQLCompare.matches" title="Link to this definition">¶</a></dt>
<dd><p>Return True or False if the dataframes match.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ignore_extra_columns</strong> (<em>bool</em>) – Ignores any columns in one dataframe and not in the other.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="datacompy.spark.sql.SparkSQLCompare.report">
<span class="sig-name descname"><span class="pre">report</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sample_count</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">column_count</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">html_file</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">template_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#datacompy.spark.sql.SparkSQLCompare.report" title="Link to this definition">¶</a></dt>
<dd><p>Return a string representation of a report.</p>
<p>The representation can then be printed or saved to a file. You can customize the
report’s appearance by providing a custom Jinja2 template.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sample_count</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of sample records to return. Defaults to 10.</p></li>
<li><p><strong>column_count</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of columns to display in the sample records output. Defaults to 10.</p></li>
<li><p><strong>html_file</strong> (<em>str</em><em>, </em><em>optional</em>) – HTML file name to save report output to. If <code class="docutils literal notranslate"><span class="pre">None</span></code> the file creation will be skipped.</p></li>
<li><p><strong>template_path</strong> (<em>str</em><em>, </em><em>optional</em>) – <p>Path to a custom Jinja2 template file to use for report generation.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the default template will be used. The template receives the
following context variables:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">column_summary</span></code>: Dict with column statistics including: <code class="docutils literal notranslate"><span class="pre">common_columns</span></code>, <code class="docutils literal notranslate"><span class="pre">df1_unique</span></code>, <code class="docutils literal notranslate"><span class="pre">df2_unique</span></code>, <code class="docutils literal notranslate"><span class="pre">df1_name</span></code>, <code class="docutils literal notranslate"><span class="pre">df2_name</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">row_summary</span></code>: Dict with row statistics including: <code class="docutils literal notranslate"><span class="pre">match_columns</span></code>, <code class="docutils literal notranslate"><span class="pre">equal_rows</span></code>, <code class="docutils literal notranslate"><span class="pre">unequal_rows</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">column_comparison</span></code>: Dict with column comparison statistics including: <code class="docutils literal notranslate"><span class="pre">unequal_columns</span></code>, <code class="docutils literal notranslate"><span class="pre">equal_columns</span></code>, <code class="docutils literal notranslate"><span class="pre">unequal_values</span></code></p></li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">mismatch_stats</span></code>: Dict containing:</dt><dd><ul>
<li><p><code class="docutils literal notranslate"><span class="pre">stats</span></code>: List of dicts with column mismatch statistics (column, match, mismatch, null_diff, etc.)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">samples</span></code>: Sample rows with mismatched values</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">has_samples</span></code>: Boolean indicating if there are any mismatch samples</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">has_mismatches</span></code>: Boolean indicating if there are any mismatches</p></li>
</ul>
</dd>
</dl>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">df1_unique_rows</span></code>: Dict with unique rows in df1 including: <code class="docutils literal notranslate"><span class="pre">has_rows</span></code>, <code class="docutils literal notranslate"><span class="pre">rows</span></code>, <code class="docutils literal notranslate"><span class="pre">columns</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">df2_unique_rows</span></code>: Dict with unique rows in df2 including: <code class="docutils literal notranslate"><span class="pre">has_rows</span></code>, <code class="docutils literal notranslate"><span class="pre">rows</span></code>, <code class="docutils literal notranslate"><span class="pre">columns</span></code></p></li>
</ul>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The report, formatted according to the template.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="datacompy.spark.sql.SparkSQLCompare.sample_mismatch">
<span class="sig-name descname"><span class="pre">sample_mismatch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">column</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_count</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">for_display</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataFrame</span></span></span><a class="headerlink" href="#datacompy.spark.sql.SparkSQLCompare.sample_mismatch" title="Link to this definition">¶</a></dt>
<dd><p>Return sample mismatches.</p>
<p>Gets a sub-dataframe which contains the identifying
columns, and df1 and df2 versions of the column.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>column</strong> (<em>str</em>) – The raw column name (i.e. without <code class="docutils literal notranslate"><span class="pre">_df1</span></code> appended)</p></li>
<li><p><strong>sample_count</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of sample records to return.  Defaults to 10.</p></li>
<li><p><strong>for_display</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether this is just going to be used for display (overwrite the
column names)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A sample of the intersection dataframe, containing only the
“pertinent” columns, for rows that don’t match on the provided
column.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>pyspark.sql.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="datacompy.spark.sql.SparkSQLCompare.subset">
<span class="sig-name descname"><span class="pre">subset</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#datacompy.spark.sql.SparkSQLCompare.subset" title="Link to this definition">¶</a></dt>
<dd><p>Return True if dataframe 2 is a subset of dataframe 1.</p>
<p>Dataframe 2 is considered a subset if all of its columns are in
dataframe 1, and all of its rows match rows in dataframe 1 for the
shared columns.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>True if dataframe 2 is a subset of dataframe 1.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="datacompy.spark.sql.calculate_max_diff">
<span class="sig-prename descclassname"><span class="pre">datacompy.spark.sql.</span></span><span class="sig-name descname"><span class="pre">calculate_max_diff</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataframe</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">col_1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">col_2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#datacompy.spark.sql.calculate_max_diff" title="Link to this definition">¶</a></dt>
<dd><p>Get a maximum difference between two columns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataframe</strong> (<em>pyspark.sql.DataFrame</em>) – DataFrame to do comparison on</p></li>
<li><p><strong>col_1</strong> (<em>str</em>) – The first column to look at</p></li>
<li><p><strong>col_2</strong> (<em>str</em>) – The second column</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>max diff</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="datacompy.spark.sql.calculate_null_diff">
<span class="sig-prename descclassname"><span class="pre">datacompy.spark.sql.</span></span><span class="sig-name descname"><span class="pre">calculate_null_diff</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataframe</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">col_1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">col_2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#datacompy.spark.sql.calculate_null_diff" title="Link to this definition">¶</a></dt>
<dd><p>Get the null differences between two columns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataframe</strong> (<em>pyspark.sql.DataFrame</em>) – DataFrame to do comparison on</p></li>
<li><p><strong>col_1</strong> (<em>str</em>) – The first column to look at</p></li>
<li><p><strong>col_2</strong> (<em>str</em>) – The second column</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>null diff</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="datacompy.spark.sql.columns_equal">
<span class="sig-prename descclassname"><span class="pre">datacompy.spark.sql.</span></span><span class="sig-name descname"><span class="pre">columns_equal</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataframe</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">col_1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">col_2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rel_tol</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">abs_tol</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_spaces</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_case</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Column</span></span></span><a class="headerlink" href="#datacompy.spark.sql.columns_equal" title="Link to this definition">¶</a></dt>
<dd><p>Compare if two columns are considered equal, returns a boolean Spark Column to be used in a <cite>.withColumn(…)</cite> statement.</p>
<p>Returns a True/False series with the same index as column 1.</p>
<ul class="simple">
<li><p>Two nulls (np.nan) will evaluate to True.</p></li>
<li><p>A null and a non-null value will evaluate to False.</p></li>
<li><p>Numeric values will use the relative and absolute tolerances.</p></li>
<li><p>Decimal values (decimal.Decimal) will attempt to be converted to floats
before comparing</p></li>
<li><p>Non-numeric values (i.e. where np.isclose can’t be used) will just
trigger True on two nulls or exact matches.</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataframe</strong> (<em>pyspark.sql.DataFrame</em>) – DataFrame to do comparison on</p></li>
<li><p><strong>col_1</strong> (<em>str</em>) – The first column to look at</p></li>
<li><p><strong>col_2</strong> (<em>str</em>) – The second column</p></li>
<li><p><strong>rel_tol</strong> (<em>float</em><em>, </em><em>optional</em>) – Relative tolerance</p></li>
<li><p><strong>abs_tol</strong> (<em>float</em><em>, </em><em>optional</em>) – Absolute tolerance</p></li>
<li><p><strong>ignore_spaces</strong> (<em>bool</em><em>, </em><em>optional</em>) – Flag to strip whitespace (including newlines) from string columns</p></li>
<li><p><strong>ignore_case</strong> (<em>bool</em><em>, </em><em>optional</em>) – Flag to ignore the case of string columns</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Boolean Spark Column: True if values match according to the rules above, False otherwise.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>pyspark.sql.Column</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">pyspark.sql</span><span class="w"> </span><span class="kn">import</span> <span class="n">SparkSession</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
<span class="gp">... </span>    <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">,</span> <span class="s2">&quot;ABC&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
<span class="gp">... </span>    <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="s2">&quot;DEF &quot;</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">),</span>
<span class="gp">... </span>    <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;ghi&quot;</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">)</span>
<span class="gp">... </span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;col1&quot;</span><span class="p">,</span> <span class="s2">&quot;col2&quot;</span><span class="p">,</span> <span class="s2">&quot;col3&quot;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Compare numeric columns with tolerance</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;col1_equals_col3&quot;</span><span class="p">,</span> <span class="n">columns_equal</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="s2">&quot;col1&quot;</span><span class="p">,</span> <span class="s2">&quot;col3&quot;</span><span class="p">,</span> <span class="n">rel_tol</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Compare string columns ignoring case and spaces</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;col2_normalized&quot;</span><span class="p">,</span> <span class="n">columns_equal</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="s2">&quot;col2&quot;</span><span class="p">,</span> <span class="s2">&quot;col2&quot;</span><span class="p">,</span> <span class="n">ignore_spaces</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ignore_case</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Starting in version 0.18.0, the behavior of this function was changed so rather than returning
a DataFrame a Column expression is returned.</p>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="datacompy.spark.sql.decimal_comparator">
<span class="sig-prename descclassname"><span class="pre">datacompy.spark.sql.</span></span><span class="sig-name descname"><span class="pre">decimal_comparator</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#datacompy.spark.sql.decimal_comparator" title="Link to this definition">¶</a></dt>
<dd><p>Check equality with decimal(X, Y) types.</p>
<p>Otherwise treated as the string “decimal”.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="datacompy.spark.sql.get_merged_columns">
<span class="sig-prename descclassname"><span class="pre">datacompy.spark.sql.</span></span><span class="sig-name descname"><span class="pre">get_merged_columns</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">original_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">merged_df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">suffix</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#datacompy.spark.sql.get_merged_columns" title="Link to this definition">¶</a></dt>
<dd><p>Get the columns from an original dataframe, in the new merged dataframe.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>original_df</strong> (<em>pyspark.sql.DataFrame</em>) – The original, pre-merge dataframe</p></li>
<li><p><strong>merged_df</strong> (<em>pyspark.sql.DataFrame</em>) – Post-merge with another dataframe, with suffixes added in.</p></li>
<li><p><strong>suffix</strong> (<em>str</em>) – What suffix was used to distinguish when the original dataframe was
overlapping with the other merged dataframe.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Column list of the original dataframe pre suffix</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[str]</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-datacompy.spark">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-datacompy.spark" title="Link to this heading">¶</a></h2>
<p>Spark comparisons.</p>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          
          <a class="prev-page" href="datacompy.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">datacompy package</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2024, Capital One
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">datacompy.spark package</a><ul>
<li><a class="reference internal" href="#submodules">Submodules</a></li>
<li><a class="reference internal" href="#module-datacompy.spark.helper">datacompy.spark.helper module</a><ul>
<li><a class="reference internal" href="#datacompy.spark.helper.compare_by_row"><code class="docutils literal notranslate"><span class="pre">compare_by_row()</span></code></a></li>
<li><a class="reference internal" href="#datacompy.spark.helper.format_numeric_fields"><code class="docutils literal notranslate"><span class="pre">format_numeric_fields()</span></code></a></li>
<li><a class="reference internal" href="#datacompy.spark.helper.handle_numeric_strings"><code class="docutils literal notranslate"><span class="pre">handle_numeric_strings()</span></code></a></li>
<li><a class="reference internal" href="#datacompy.spark.helper.sort_columns"><code class="docutils literal notranslate"><span class="pre">sort_columns()</span></code></a></li>
<li><a class="reference internal" href="#datacompy.spark.helper.sort_rows"><code class="docutils literal notranslate"><span class="pre">sort_rows()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-datacompy.spark.sql">datacompy.spark.sql module</a><ul>
<li><a class="reference internal" href="#datacompy.spark.sql.SparkSQLCompare"><code class="docutils literal notranslate"><span class="pre">SparkSQLCompare</span></code></a><ul>
<li><a class="reference internal" href="#datacompy.spark.sql.SparkSQLCompare.all_columns_match"><code class="docutils literal notranslate"><span class="pre">SparkSQLCompare.all_columns_match()</span></code></a></li>
<li><a class="reference internal" href="#datacompy.spark.sql.SparkSQLCompare.all_mismatch"><code class="docutils literal notranslate"><span class="pre">SparkSQLCompare.all_mismatch()</span></code></a></li>
<li><a class="reference internal" href="#datacompy.spark.sql.SparkSQLCompare.all_rows_overlap"><code class="docutils literal notranslate"><span class="pre">SparkSQLCompare.all_rows_overlap()</span></code></a></li>
<li><a class="reference internal" href="#datacompy.spark.sql.SparkSQLCompare.count_matching_rows"><code class="docutils literal notranslate"><span class="pre">SparkSQLCompare.count_matching_rows()</span></code></a></li>
<li><a class="reference internal" href="#datacompy.spark.sql.SparkSQLCompare.df1"><code class="docutils literal notranslate"><span class="pre">SparkSQLCompare.df1</span></code></a></li>
<li><a class="reference internal" href="#datacompy.spark.sql.SparkSQLCompare.df1_unq_columns"><code class="docutils literal notranslate"><span class="pre">SparkSQLCompare.df1_unq_columns()</span></code></a></li>
<li><a class="reference internal" href="#datacompy.spark.sql.SparkSQLCompare.df2"><code class="docutils literal notranslate"><span class="pre">SparkSQLCompare.df2</span></code></a></li>
<li><a class="reference internal" href="#datacompy.spark.sql.SparkSQLCompare.df2_unq_columns"><code class="docutils literal notranslate"><span class="pre">SparkSQLCompare.df2_unq_columns()</span></code></a></li>
<li><a class="reference internal" href="#datacompy.spark.sql.SparkSQLCompare.intersect_columns"><code class="docutils literal notranslate"><span class="pre">SparkSQLCompare.intersect_columns()</span></code></a></li>
<li><a class="reference internal" href="#datacompy.spark.sql.SparkSQLCompare.intersect_rows_match"><code class="docutils literal notranslate"><span class="pre">SparkSQLCompare.intersect_rows_match()</span></code></a></li>
<li><a class="reference internal" href="#datacompy.spark.sql.SparkSQLCompare.matches"><code class="docutils literal notranslate"><span class="pre">SparkSQLCompare.matches()</span></code></a></li>
<li><a class="reference internal" href="#datacompy.spark.sql.SparkSQLCompare.report"><code class="docutils literal notranslate"><span class="pre">SparkSQLCompare.report()</span></code></a></li>
<li><a class="reference internal" href="#datacompy.spark.sql.SparkSQLCompare.sample_mismatch"><code class="docutils literal notranslate"><span class="pre">SparkSQLCompare.sample_mismatch()</span></code></a></li>
<li><a class="reference internal" href="#datacompy.spark.sql.SparkSQLCompare.subset"><code class="docutils literal notranslate"><span class="pre">SparkSQLCompare.subset()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#datacompy.spark.sql.calculate_max_diff"><code class="docutils literal notranslate"><span class="pre">calculate_max_diff()</span></code></a></li>
<li><a class="reference internal" href="#datacompy.spark.sql.calculate_null_diff"><code class="docutils literal notranslate"><span class="pre">calculate_null_diff()</span></code></a></li>
<li><a class="reference internal" href="#datacompy.spark.sql.columns_equal"><code class="docutils literal notranslate"><span class="pre">columns_equal()</span></code></a></li>
<li><a class="reference internal" href="#datacompy.spark.sql.decimal_comparator"><code class="docutils literal notranslate"><span class="pre">decimal_comparator()</span></code></a></li>
<li><a class="reference internal" href="#datacompy.spark.sql.get_merged_columns"><code class="docutils literal notranslate"><span class="pre">get_merged_columns()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-datacompy.spark">Module contents</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=6f83b549"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=46bd48cc"></script>
    </body>
</html>